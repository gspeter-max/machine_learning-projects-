{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1️⃣ Load data (Parquet/CSV).\\n2️⃣ Feature Engineering (convert media_type to numerical, extract day/hour from timestamp).\\n3️⃣ Assemble features using VectorAssembler.\\n4️⃣ Train a Random Forest model (regression or classification).\\n5️⃣ Evaluate model performance (RMSE for regression, Accuracy/AUC for classification).\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1️⃣ Load data (Parquet/CSV).\n",
    "2️⃣ Feature Engineering (convert media_type to numerical, extract day/hour from timestamp).\n",
    "3️⃣ Assemble features using VectorAssembler.\n",
    "4️⃣ Train a Random Forest model (regression or classification).\n",
    "5️⃣ Evaluate model performance (RMSE for regression, Accuracy/AUC for classification).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import  SparkSession \n",
    "\n",
    "# spark = SparkSession.builder.appName('pipeline').getOrCreate() \n",
    "\n",
    "# df_csv = spark.read.csv('/workspaces/machine_learning-projects-/pending_work/pyspark task/small_media_data.csv',\n",
    "#                         header = True, inferSchema = True)\n",
    "\n",
    "# num_partitions = df_csv.rdd.getNumPartitions()  \n",
    "# print(num_partitions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_csv = df_csv.repartition(num_partitions + 10)\n",
    "df_csv.write.option('compression','snappy').mode('overwrite').parquet('/workspaces/machine_learning-projects-/pending_work/pyspark task/small_media_data.parquet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+-----+------+--------+------------------+------+----------------+\n",
      "|post_id|user_id|      date|likes|shares|comments|media_type_encoded|months|engagement_score|\n",
      "+-------+-------+----------+-----+------+--------+------------------+------+----------------+\n",
      "|    371|    126|2025-03-12|  516|   473|       5|                 1|     3|               1|\n",
      "|    997|     34|2025-03-05|  259|   266|     208|                 2|     3|               0|\n",
      "|    823|    105|2025-03-02|  462|    62|     241|                 1|     3|               0|\n",
      "|    771|    103|2025-03-22|  845|     1|     274|                 3|     3|               1|\n",
      "|    594|     17|2025-03-23|  212|   156|     182|                 3|     3|               0|\n",
      "|    133|      8|2025-03-13|  123|   313|     182|                 3|     3|               0|\n",
      "|    321|     47|2025-03-12|  811|    20|     132|                 2|     3|               1|\n",
      "|    928|     57|2025-03-04|  771|   277|     250|                 3|     3|               1|\n",
      "|    529|     92|2025-03-06|  982|   263|     178|                 2|     3|               1|\n",
      "|     29|     57|2025-03-26|  601|   244|      81|                 3|     3|               1|\n",
      "|    514|     62|2025-03-01|  286|   375|     115|                 3|     3|               0|\n",
      "|    757|    122|2025-03-09|  287|   265|      62|                 2|     3|               0|\n",
      "|    237|    190|2025-02-25|  438|    65|      64|                 1|     2|               0|\n",
      "|      2|     51|2025-03-21|  426|   398|     245|                 3|     3|               0|\n",
      "|    735|     54|2025-03-08|  616|   146|     144|                 3|     3|               1|\n",
      "|     73|     63|2025-03-14|  710|   413|      36|                 2|     3|               1|\n",
      "|     67|     84|2025-02-27|  454|    30|      29|                 1|     2|               0|\n",
      "|    659|     15|2025-03-19|  954|   294|     127|                 1|     3|               1|\n",
      "|    484|    123|2025-03-05|  916|   386|     187|                 3|     3|               1|\n",
      "|    837|    159|2025-02-26|  352|   439|      60|                 2|     2|               0|\n",
      "+-------+-------+----------+-----+------+--------+------------------+------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet = spark.read.parquet('/workspaces/machine_learning-projects-/pending_work/pyspark task/small_media_data.parquet')\n",
    "\n",
    "\n",
    "'''\n",
    "# if you do that in sql \n",
    "\n",
    "df_parquet.createOrReplaceTempView('media_table')\n",
    "df_parquet = spark.sql(\n",
    "    \"\"\"\n",
    "        with temp_temp as (\n",
    "            select \n",
    "                post_id, \n",
    "                user_id, \n",
    "                cast(timestamp as date) as dates, \n",
    "                cast(date_format(timestamp,\"M\") as int)  as months , \n",
    "                likes, \n",
    "                case when likes > 500 then 1 else 0 end as engagement_score, \n",
    "                case when media_type = 'image' then 1 \n",
    "                    when media_type = 'text' then 2 \n",
    "                    else 3 end as media_type_encoded\n",
    "\n",
    "            from media_table \n",
    "        )\n",
    "        select * from temp_temp;\n",
    "    \"\"\"\n",
    ")\n",
    "'''\n",
    "\n",
    "from pyspark.sql.functions import when,cast , col , date_format,cast \n",
    "from pyspark.sql.types  import DateType  \n",
    "\n",
    "df_parquet = df_parquet.withColumn('timestamp' , col('timestamp').cast(DateType())).withColumnRenamed('timestamp','date')\n",
    "df_parquet = df_parquet.withColumn('months' , date_format('date', 'M').cast('int'))\n",
    "df_parquet= df_parquet.withColumn('engagement_score', when(col('likes') > 500 ,1).otherwise(0))\n",
    "df_parquet = df_parquet.withColumn('media_type',when(col('media_type') == 'image', 1).when(col('media_type') == 'video',2).otherwise(3)).withColumnRenamed('media_type', 'media_type_encoded')\n",
    "df_parquet.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train , test = df_parquet.randomSplit([0.8,0.2], seed= 42)\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import  RandomForestClassifier\n",
    "\n",
    "train = train.drop('post_id','user_id','date')\n",
    "\n",
    "column_list = train.columns\n",
    "column_list.remove('engagement_score')\n",
    "\n",
    "vector = VectorAssembler(\n",
    "    inputCols = column_list,\n",
    "    outputCol = 'vector_list'\n",
    ")\n",
    "train_transformed = vector.transform(train)\n",
    "test_transformed = vector.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RandomForestClassifier(\n",
    "    featuresCol = 'vector_list', \n",
    "    labelCol = 'engagement_score'\n",
    ")\n",
    "model = model.fit(train_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+-----+------+--------+------------------+------+----------------+--------------------+--------------------+--------------------+----------+\n",
      "|post_id|user_id|      date|likes|shares|comments|media_type_encoded|months|engagement_score|         vector_list|       rawPrediction|         probability|prediction|\n",
      "+-------+-------+----------+-----+------+--------+------------------+------+----------------+--------------------+--------------------+--------------------+----------+\n",
      "|      3|     29|2025-03-23|  969|   197|     148|                 3|     3|               1|[969.0,197.0,148....|[0.03698201760166...|[0.00184910088008...|       1.0|\n",
      "|      8|      1|2025-03-14|  537|   358|      45|                 2|     3|               1|[537.0,358.0,45.0...|[0.55787569833490...|[0.02789378491674...|       1.0|\n",
      "|     12|     90|2025-03-10|  880|   324|     146|                 3|     3|               1|[880.0,324.0,146....|[0.04165491479792...|[0.00208274573989...|       1.0|\n",
      "|     29|     57|2025-03-26|  601|   244|      81|                 3|     3|               1|[601.0,244.0,81.0...|[0.02477470749315...|[0.00123873537465...|       1.0|\n",
      "|     40|    135|2025-03-07|  687|   467|     293|                 3|     3|               1|[687.0,467.0,293....|[0.04601653755851...|[0.00230082687792...|       1.0|\n",
      "|     47|    108|2025-03-11|  970|    69|     213|                 2|     3|               1|[970.0,69.0,213.0...|[0.01220731010850...|[6.10365505425471...|       1.0|\n",
      "|     60|    150|2025-03-16|  278|   296|      56|                 2|     3|               0|[278.0,296.0,56.0...|[19.5284280936454...|[0.97642140468227...|       0.0|\n",
      "|     71|    118|2025-03-10|   64|    35|     291|                 3|     3|               0|[64.0,35.0,291.0,...|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|     91|    168|2025-03-23|  621|   105|     289|                 3|     3|               1|[621.0,105.0,289....|[0.03212764866962...|[0.00160638243348...|       1.0|\n",
      "|     96|    115|2025-03-16|  776|   328|     187|                 2|     3|               1|[776.0,328.0,187....|[0.04165491479792...|[0.00208274573989...|       1.0|\n",
      "|     98|    194|2025-03-25|   84|   227|     289|                 2|     3|               0|[84.0,227.0,289.0...|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    100|    114|2025-03-20|  327|   106|      60|                 1|     3|               0|[327.0,106.0,60.0...|[19.5284280936454...|[0.97642140468227...|       0.0|\n",
      "|    102|    179|2025-03-20|  449|   337|     122|                 1|     3|               0|[449.0,337.0,122....|[19.5284280936454...|[0.97642140468227...|       0.0|\n",
      "|    108|     55|2025-02-28|  664|   177|     143|                 3|     2|               1|[664.0,177.0,143....|[0.03698201760166...|[0.00184910088008...|       1.0|\n",
      "|    120|    135|2025-02-26|  342|   471|     220|                 3|     2|               0|[342.0,471.0,220....|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    133|      8|2025-03-13|  123|   313|     182|                 3|     3|               0|[123.0,313.0,182....|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    143|    196|2025-03-12|  469|   402|     177|                 1|     3|               0|[469.0,402.0,177....|          [19.0,1.0]|         [0.95,0.05]|       0.0|\n",
      "|    176|    166|2025-03-21|  908|   197|     146|                 1|     3|               1|[908.0,197.0,146....|[0.55805717007067...|[0.02790285850353...|       1.0|\n",
      "|    193|     40|2025-03-11|  171|   166|     212|                 3|     3|               0|[171.0,166.0,212....|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    202|    109|2025-03-12|  117|   137|     200|                 1|     3|               0|[117.0,137.0,200....|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "+-------+-------+----------+-----+------+--------+------------------+------+----------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "roc : 0.9950062421972535\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import  BinaryClassificationEvaluator\n",
    "\n",
    "prediction = model.transform(test_transformed)\n",
    "prediction.show()\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol = 'engagement_score',\n",
    "    rawPredictionCol = 'probability', \n",
    "    metricName = 'areaUnderROC'\n",
    ")\n",
    "roc = evaluator.evaluate(prediction)\n",
    "print(f'roc : {roc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
